# Generative Model

**üìãCatalogue**


**üî¨Resources**


## ü™µ AR

| Date   | Title                                                                                          | Summary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | Links                                                                                                                                                                                                                                                                                             |
| ------ | ---------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 2024   | **Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction** \| VAR | <sub>Proposed **Visual AutoRegressive modeling (VAR)**, as **coarse-to-fine** ‚Äú**next-scale** prediction‚Äù. First, it uses a **multi-scale VQ auto-encoder** encodes an image into K token maps with **different** **resolutions**. Then it utilizes **a VAR transformer** to execute **the next-scale prediction**. Specifically, the **autoregressive unit** is an **entire token map**, rather than **a single token**. The **attention mask** is used in training to fulfill causal attention and standard cross-entropy loss is used. The **implementing framework** of **VAR** is derived from **VQ-GAN**. **VAR**, the visual generative model can be viewed as a combination of **VQ-VAE** and **Transformer**(**VR**). ‚≠ê\|üå∏\|‚ù§Ô∏è‚Äçüî•\|üëçüèª\|ü§®</sub> | <div style='width:150px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](https://arxiv.org/abs/2404.02905)</div><div style='width:150px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/FoundationVision/VAR)</div> |
| 2024/6 | **ControlVAR: Exploring Controllable Visual Autoregressive Modeling** \| ControlVAR            | <sub>Following **the next-scale autoregressive** paradigm, **ControlVAR** explores the incorporation of **additional controls**(A **teacher-forcing** **guidance** strategy) into the **modeling** process. It's a an **autoregressive** **Transformer** framework, using the following as **conditions** : **image**, **pixel-level control** and **token-level control**.  üí´\|üå∑\|üî•\|üëçüèΩ\|üòâ</sub>                                                                                                                                                                                                                                                                                                                                                     | <div style='width:150px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](https://arxiv.org/abs/2406.09750v1)</div>                                                                                                                                                     |
|        |                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |                                                                                                                                                                                                                                                                                                   |



## ü™µ VAE

| Date         | Title                                                                     | Summary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | Links                                                                                                                                       |
| ------------ | ------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------- |
| ICLR<br>2014 | **Auto-Encoding Variational Bayes** \| VAE                                | <sub> Unifying Count-Based Exploration and Intrinsic MotivationUnifying Count-Based Exploration and Intrinsic MotivationUnifying Count-Based Exploration and Intrinsic </sub>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | <div style='width:150px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](https://arxiv.org/abs/1312.6114)</div>  |
| NIPS<br>2017 | **Neural Discrete Representation Learning** \| VQ-VAE                     | <sub>Proposed the **Vector Quantized**-Variational AutoEncoder (**VQ-VAE**). The posterior and prior distributions are categorical, and the samples drawn from these distributions index an **embedding table**. These **embeddings** are then used as input into the decoder network. üåü\|üå∫\|üë©‚Äçüöí\|üëçüèª\|ü§î</sub>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       | <div style='width:150px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](https://arxiv.org/abs/1711.00937)</div> |
| CVPR<br>2022 | **Autoregressive Image Generation using Residual Quantization** \| RQ-VAE | <sub>**Previous** VQ cannot **simultaneously** **shorten** the code sequence and generate **high-fidelity** images in the rate-distortion trade-off, so it proposed the idea of **Residual-Quantized**. Specifically, given a fixed codebook size, 1Ô∏è‚É£ **RQVAE** can approximate **a feature map** of an image and represent the image as a **stacked** map of **discrete codes**.  2Ô∏è‚É£ **RQ-Transformer**, **spatial transformer** learns to predict the quantized feature vector at **the next position**, and the **depth transformer** autoregressively predicts **D codes** **at position t**. The **recursive quantization** of RQ approximates the vector in **a coarse-to-fine** manner. And **a single shared codebook** is used for **every** quantization **depth**. üí´\|üå∑\|‚òÑÔ∏è\|üëçüèΩ\|üòâ</sub> | <div style='width:150px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](https://arxiv.org/abs/2203.01941)</div> |
|              |                                                                           |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |                                                                                                                                             |
|              |                                                                           |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |                                                                                                                                             |



## ü™µ GAN

| Date                 | Title                                                                 | Summary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | Links                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
| -------------------- | --------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| CVPR<br>2021<br>oral | **Taming Transformers for High-Resolution Image Synthesis** \| VQ-GAN | <sub>Proposed **VQ-GAN**, an image **generative** model that **combines** **GAN**, **VQ-VAE** and **Transformer**. Specifically, there're two stages. 1Ô∏è‚É£ **GAN** :  First it utilizes a VQ-VAE, which is viewed as a generator to construct a **codebook**. Furthermore, it uses a **discriminator** to differentiate between **real** and **reconstructed** images. When put together, we obtain the **discrete capabilities** of VQ, the **rich expressivity** of GANs, and the **encoding capabilities** of the autoencoder. 2Ô∏è‚É£ **Transformer** : On top of the **codebook**, it'll learn **long-range interactions** across visual parts through the **Transformer**. Beyond the above, it also uses some tricks like **perceptual loss** for good perceptual quality at increased compression rate, and **sliding-window** for high-resolution images. üí´\|üå∏\|‚ù§Ô∏è‚Äçüî•\|üëçüèª\|ü§®</sub> | <div style='width:150px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](https://arxiv.org/abs/2012.09841)</div><div style='width:150px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/CompVis/taming-transformers)</div><div style='width:150px;'>[![Blog](https://img.shields.io/badge/Blog-Website-yellow?logo=rss)](https://compvis.github.io/taming-transformers/)</div> |
|                      |                                                                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |                                                                                                                                                                                                                                                                                                                                                                                                                                                              |


## ü™µ Diffusion

| Date                 | Title                                                                                            | Summary                                                                                                                                                                                                                                                                                      | Links                                                                                                                                                                                                                                                                                                                                                                                                                                              |
| -------------------- | ------------------------------------------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| ICML<br>2015         | **Deep Unsupervised Learning using Nonequilibrium Thermodynamics**                               | <sub>Unifying Count-Based Exploration and Intrinsic MotivationUnifying Count-Based Exploration and Intrinsic MotivationUnifying Count-Based Exploration and Intrinsic </sub>                                                                                                                 |                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| NIPS<br>2019         | **Generative Modeling by Estimating Gradients of the Data Distribution**                         | <sub>Unifying Count-Based Exploration and Intrinsic MotivationUnifying Count-Based Exploration and Intrinsic MotivationUnifying Count-Based Exploration and Intrinsic </sub>                                                                                                                 |                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| NIPS<br>2020         | **Improved Techniques for Training Score-Based Generative Models**                               | <sub>Unifying Count-Based Exploration and Intrinsic MotivationUnifying Count-Based Exploration and Intrinsic MotivationUnifying Count-Based Exploration and Intrinsic </sub>                                                                                                                 |                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| NIPS<br>2020         | **Denoising Diffusion Probabilistic Models** \| DDPM                                             | <sub>Proposed **DDPM**, a class of **latent variable models** inspired by considerations from **nonequilibrium thermodynamics**, which builds a connection between **diffusion probabilistic models** and **denoising score matching with Langevin dynamics**. üåü\|üå∫\|‚ù§Ô∏è‚Äçüî•\|üëçüèª\|üòâ</sub> | <div style='width:150px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](https://arxiv.org/abs/2006.11239)</div><div style='width:150px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/hojonathanho/diffusion)</div><div style='width:150px;'>[![Blog](https://img.shields.io/badge/Blog-Website-yellow?logo=rss)](https://hojonathanho.github.io/diffusion/)</div> |
| ICML<br>2021         | **Improved Denoising Diffusion Probabilistic Models** \| iDDPM                                   | <sub>Unifying Count-Based Exploration and Intrinsic MotivationUnifying Count-Based Exploration and Intrinsic MotivationUnifying Count-Based Exploration and Intrinsic </sub>                                                                                                                 | <div style='width:150px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](https://arxiv.org/abs/2102.09672)</div>                                                                                                                                                                                                                                                                                                        |
| ICLR<br>2021         | **Score-Based Generative Modeling through Stochastic Differential Equations** \| Score-Based SDE | <sub>Unifying Count-Based Exploration and Intrinsic MotivationUnifying Count-Based Exploration and Intrinsic MotivationUnifying Count-Based Exploration and Intrinsic </sub>                                                                                                                 | <div style='width:150px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](https://arxiv.org/abs/2011.13456)</div><div style='width:150px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/FoundationVision/VAR)</div>                                                                                                                                                  |
| ICLR<br>2021         | **Denoising Diffusion Implicit Models** \| DDIM                                                  | <sub>Unifying Count-Based Exploration and Intrinsic MotivationUnifying Count-Based Exploration and Intrinsic MotivationUnifying Count-Based Exploration and Intrinsic </sub>                                                                                                                 |                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| ICCV<br>2023<br>oral | **Scalable Diffusion Models with Transformers** \| DiT                                           | <sub>Unifying Count-Based Exploration and Intrinsic MotivationUnifying Count-Based Exploration and Intrinsic MotivationUnifying Count-Based Exploration and Intrinsic </sub>                                                                                                                 | <div style='width:150px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](https://arxiv.org/abs/2212.09748)</div><div style='width:150px;'>[![Blog](https://img.shields.io/badge/Blog-Website-yellow?logo=rss)](https://www.wpeebles.com/DiT.html)</div>                                                                                                                                                                 |
| ICML<br>2023         | **Consistency Models**                                                                           | <sub>Unifying Count-Based Exploration and Intrinsic MotivationUnifying Count-Based Exploration and Intrinsic MotivationUnifying Count-Based Exploration and Intrinsic </sub>                                                                                                                 |                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
|                      |                                                                                                  |                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
|                      |                                                                                                  |                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                                    |




## Standard

| Date             | Title                                                                                                          | Summary                                                                                                                                                                     | Links                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |
| ---------------- | -------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 7/4/23<br>ICML23 | **Rejection Improves Reliability: Training LLMs to Refuse Unknown Questions Using RL from Knowledge Feedback** | <sub>Unifying Count-Based Exploration and Intrinsic MotivationUnifying Count-Based Exploration and Intrinsic MotivationUnifying Count-Based Exploration and Intrinsic</sub> | <div style='width:150px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](https://cdn.openai.com/papers/weak-to-strong-generalization.pdf)</div><div style='width:150px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/openai/weak-to-strong)</div><div style='width:150px;'>[![Blog](https://img.shields.io/badge/Blog-Website-yellow?logo=rss)](https://mp.weixin.qq.com/s/f6YW-CxnLhnfMWTLg4M4Cw)</div><div style='width:150px;'>[![Note](https://img.shields.io/badge/Note-Read-blue?logo=dependabot)](summary/2024-03/2403.18349.md)</div> |
|                  |                                                                                                                |                                                                                                                                                                             |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |
